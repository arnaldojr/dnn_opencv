{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "suburban-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "sized-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "# load the COCO class names\n",
    "with open('./src/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "    \n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "peripheral-georgia",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-wvn_it83\\opencv\\modules\\dnn\\src\\tensorflow\\tf_importer.cpp:586: error: (-2:Unspecified error) Const input blob for weights not found in function 'cv::dnn::dnn4_v20201117::`anonymous-namespace'::TFImporter::getConstBlob'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-70d70bdb1f43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load the DNN model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model = cv2.dnn.readNet(model='./src/frozen_inference_graph.pb',\n\u001b[0m\u001b[0;32m      3\u001b[0m                         config='./src/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt',framework='TensorFlow')\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-wvn_it83\\opencv\\modules\\dnn\\src\\tensorflow\\tf_importer.cpp:586: error: (-2:Unspecified error) Const input blob for weights not found in function 'cv::dnn::dnn4_v20201117::`anonymous-namespace'::TFImporter::getConstBlob'\n"
     ]
    }
   ],
   "source": [
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='./src/frozen_inference_graph.pb',\n",
    "                        config='./src/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt',framework='TensorFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image from disk\n",
    "image = cv2.imread('../../input/image_2.jpg')\n",
    "image_height, image_width, _ = image.shape\n",
    "# create blob from image\n",
    "blob = cv2.dnn.blobFromImage(image=image, size=(300, 300), mean=(104, 117, 123), swapRB=True)\n",
    "# set the blob to the model\n",
    "model.setInput(blob)\n",
    "# forward pass through the model to carry out the detection\n",
    "output = model.forward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-layer",
   "metadata": {},
   "source": [
    "Looping Over the Detections and Drawing the Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each of the detection\n",
    "for detection in output[0, 0, :, :]:\n",
    "   # extract the confidence of the detection\n",
    "   confidence = detection[2]\n",
    "   # draw bounding boxes only if the detection confidence is above...\n",
    "   # ... a certain threshold, else skip\n",
    "   if confidence > .4:\n",
    "       # get the class id\n",
    "       class_id = detection[1]\n",
    "     # map the class id to the class\n",
    "       class_name = class_names[int(class_id)-1]\n",
    "       color = COLORS[int(class_id)]\n",
    "       # get the bounding box coordinates\n",
    "       box_x = detection[3] * image_width\n",
    "       box_y = detection[4] * image_height\n",
    "       # get the bounding box width and height\n",
    "       box_width = detection[5] * image_width\n",
    "       box_height = detection[6] * image_height\n",
    "       # draw a rectangle around each detected object\n",
    "       cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=2)\n",
    "       # put the FPS text on top of the frame\n",
    "       cv2.putText(image, class_name, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "cv2.imshow('image', image)\n",
    "cv2.imwrite('image_result.jpg', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-muscle",
   "metadata": {},
   "source": [
    "Object Detection in Videos using OpenCV DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    " \n",
    "# load the COCO class names\n",
    "with open('object_detection_classes_coco.txt', 'r') as f:\n",
    "   class_names = f.read().split('\\n')\n",
    " \n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    " \n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='frozen_inference_graph.pb',                        config='ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt',framework='TensorFlow')\n",
    " \n",
    "# capture the video\n",
    "cap = cv2.VideoCapture('../../input/video_1.mp4')\n",
    "# get the video frames' width and height for proper saving of videos\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "# create the `VideoWriter()` object\n",
    "out = cv2.VideoWriter('video_result.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-cloud",
   "metadata": {},
   "source": [
    "Looping Over the Video Frames and Detecting Objects in Each Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "decent-internet",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-617af8d8d613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# detect objects in each frame of the video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m    \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# detect objects in each frame of the video\n",
    "while cap.isOpened():\n",
    "   ret, frame = cap.read()\n",
    "   if ret:\n",
    "       image = frame\n",
    "       image_height, image_width, _ = image.shape\n",
    "       # create blob from image\n",
    "       blob = cv2.dnn.blobFromImage(image=image, size=(300, 300), mean=(104, 117, 123), swapRB=True)\n",
    "       # start time to calculate FPS\n",
    "       start = time.time()\n",
    "       model.setInput(blob)\n",
    "       output = model.forward()       \n",
    "       # end time after detection\n",
    "       end = time.time()\n",
    "       # calculate the FPS for current frame detection\n",
    "       fps = 1 / (end-start)\n",
    "       # loop over each of the detections\n",
    "       for detection in output[0, 0, :, :]:\n",
    "           # extract the confidence of the detection\n",
    "           confidence = detection[2]\n",
    "           # draw bounding boxes only if the detection confidence is above...\n",
    "           # ... a certain threshold, else skip\n",
    "           if confidence > .4:\n",
    "               # get the class id\n",
    "               class_id = detection[1]\n",
    "               # map the class id to the class\n",
    "               class_name = class_names[int(class_id)-1]\n",
    "               color = COLORS[int(class_id)]\n",
    "               # get the bounding box coordinates\n",
    "               box_x = detection[3] * image_width\n",
    "               box_y = detection[4] * image_height\n",
    "               # get the bounding box width and height\n",
    "               box_width = detection[5] * image_width\n",
    "               box_height = detection[6] * image_height\n",
    "               # draw a rectangle around each detected object\n",
    "               cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=2)\n",
    "               # put the class name text on the detected object\n",
    "               cv2.putText(image, class_name, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "               # put the FPS text on top of the frame\n",
    "               cv2.putText(image, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "      \n",
    "       cv2.imshow('image', image)\n",
    "       out.write(image)\n",
    "       if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "           break\n",
    "   else:\n",
    "       break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-error",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
