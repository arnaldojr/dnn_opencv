{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "czech-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "secure-battery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', '']\n"
     ]
    }
   ],
   "source": [
    "# load the COCO class names\n",
    "with open('./src/coco.names', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "    \n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "internal-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='./src/yolov3.weights',\n",
    "                        config='./src/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "legitimate-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = model.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in model.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "secure-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image from disk\n",
    "image = cv2.imread('./img/cows.jpg')\n",
    "height, width, channels = image.shape\n",
    "\n",
    "# create blob from image\n",
    "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "# set the blob to the model\n",
    "model.setInput(blob)\n",
    "# forward pass through the model to carry out the detection\n",
    "output = model.forward(output_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cloudy-newton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2]\n",
      " [21]\n",
      " [17]\n",
      " [ 9]\n",
      " [24]\n",
      " [ 0]\n",
      " [12]\n",
      " [ 5]\n",
      " [14]\n",
      " [ 7]\n",
      " [18]\n",
      " [23]\n",
      " [ 6]\n",
      " [ 4]\n",
      " [22]\n",
      " [28]\n",
      " [15]\n",
      " [ 8]]\n"
     ]
    }
   ],
   "source": [
    "# Showing informations on the screen\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in output:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "print(indexes)\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(class_names[class_ids[i]])\n",
    "        color = COLORS[class_ids[i]]\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(image, label, (x, y + 30), font, 2, color, 1)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-collect",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "processed-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# load the COCO class names\n",
    "with open('./src/coco.names', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "    \n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='./src/yolov3.weights',\n",
    "                        config='./src/yolov3.cfg')\n",
    "\n",
    "layer_names = model.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in model.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "#vs = cv2.VideoCapture('./video/vtest.avi')\n",
    "vs = cv2.VideoCapture('./video/walking.mp4')\n",
    "#vs = cv2.VideoCapture(0)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "starting_time = time.time()\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    (grabbed, frame) = vs.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "    frame_id += 1\n",
    "    height, width, channels = frame.shape\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "    # set the blob to the model\n",
    "    model.setInput(blob)\n",
    "    # forward pass through the model to carry out the detection\n",
    "    output = model.forward(output_layers)\n",
    "    \n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in output:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.8, 0.3)\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(class_names[class_ids[i]])\n",
    "            confidence = confidences[i]\n",
    "            color = COLORS[class_ids[i]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label + \" \" + str(round(confidence, 2)), (x, y + 30), font, 1, color, 1)\n",
    "\n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps = frame_id / elapsed_time\n",
    "    cv2.putText(frame, \"FPS: \" + str(round(fps, 2)), (10, 50), font, 4, (0, 0, 0), 2)\n",
    "    cv2.imshow('image', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-montgomery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
